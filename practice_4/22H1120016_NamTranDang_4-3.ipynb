{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "22H1120016 - Trần Đăng Nam\n",
    "\n",
    "Gom cụm văn bản với K-Means trên 20 Newsgroups Dataset\n",
    "\n",
    "Dùng dataset: https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_20newsgroups.html\n",
    "\n",
    "# Mục tiêu:\n",
    "1. Nạp dữ liệu từ 3 nhóm tin cụ thể: 'sci.space', 'soc.religion.christian', 'talk.politics.guns'.\n",
    "\n",
    "2. Tiền xử lý và vector hóa văn bản bằng TF-IDF.\n",
    "\n",
    "3. Áp dụng thuật toán K-Means để gom cụm các tài liệu thành 3 nhóm.\n",
    "\n",
    "4. Đánh giá chất lượng gom cụm bằng các độ đo phổ biến."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from time import time\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "import logging\n",
    "\n",
    "# Cấu hình logging để xem thông tin (tùy chọn)\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s %(levelname)s %(message)s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 14:18:40,441 INFO Downloading 20news dataset. This may take a few minutes.\n",
      "2025-03-30 14:18:40,444 INFO Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đang nạp dữ liệu 20 newsgroups cho các nhóm tin:\n",
      "['sci.space', 'soc.religion.christian', 'talk.politics.guns']\n",
      "2894 tài liệu được nạp.\n",
      "3 nhóm tin.\n",
      "Số lượng cụm thực tế (số nhóm tin): 3\n"
     ]
    }
   ],
   "source": [
    "# 2. Nạp dữ liệu (3 lớp theo yêu cầu)\n",
    "# `fetch_20newsgroups` sẽ tải dữ liệu nếu chưa có và lưu vào cache.\n",
    "# Tham số `remove` giúp loại bỏ các phần không mong muốn như header, footer, quote để tập trung vào nội dung chính.\n",
    "\n",
    "# Định nghĩa các nhóm tin cần lấy\n",
    "categories = [\n",
    "    'sci.space',\n",
    "    'soc.religion.christian',\n",
    "    'talk.politics.guns',\n",
    "]\n",
    "\n",
    "print(\"Đang nạp dữ liệu 20 newsgroups cho các nhóm tin:\")\n",
    "print(categories)\n",
    "\n",
    "# Nạp dữ liệu, chỉ lấy phần 'all' (bao gồm cả train và test)\n",
    "dataset = fetch_20newsgroups(\n",
    "    subset='all',  # Lấy cả tập train và test gộp lại\n",
    "    categories=categories,\n",
    "    shuffle=True,  # Mix dữ liệu để tạo random\n",
    "    random_state=42, \n",
    "    remove=('headers', 'footers', 'quotes') # Loại bỏ các thứ k dùng - chỉ lấy nội dung \n",
    ")\n",
    "\n",
    "print(f\"{len(dataset.data)} tài liệu được nạp.\")\n",
    "print(f\"{len(dataset.target_names)} nhóm tin.\")\n",
    "\n",
    "# dataset.data: list chứa nội dung các tài liệu (văn bản)\n",
    "# dataset.target: numpy array chứa chỉ số của nhóm tin thật sự của mỗi tài liệu (0, 1, 2)\n",
    "# dataset.target_names: list tên các nhóm tin tương ứng với chỉ số target\n",
    "\n",
    "# Lưu lại nhãn thật để đánh giá sau này\n",
    "labels_true = dataset.target\n",
    "n_clusters_true = np.unique(labels_true).shape[0] # Số lượng nhóm tin thật sự (phải là 3)\n",
    "\n",
    "print(f\"Số lượng cụm thực tế (số nhóm tin): {n_clusters_true}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-Means hoạt động trên dữ liệu số. Chúng ta cần chuyển đổi văn bản thành các vector số.\n",
    "TF-IDF (Term Frequency-Inverse Document Frequency) là một kỹ thuật phổ biến để làm điều này.\n",
    "- **TF (Term Frequency):** Tần suất xuất hiện của một từ trong một tài liệu.\n",
    "- **IDF (Inverse Document Frequency):** Độ đo mức độ quan trọng của một từ. Từ nào xuất hiện trong nhiều tài liệu sẽ có IDF thấp và ngược lại.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trích xuất đặc trưng bằng TF-IDF Vectorizer...\n",
      "Hoàn thành trong 0.366s\n",
      "Số lượng mẫu (tài liệu): 2894, Số lượng đặc trưng (từ): 15778\n",
      "Kích thước ma trận TF-IDF: (2894, 15778)\n"
     ]
    }
   ],
   "source": [
    "# 3. Vector hóa văn bản bằng TF-IDF\n",
    "\n",
    "print(\"Trích xuất đặc trưng bằng TF-IDF Vectorizer...\")\n",
    "t0 = time()\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_df=0.5, # Bỏ từ xuất hiện > 50% tài liệu\n",
    "    min_df=2,   # Bỏ từ xuất hiện < 2 tài liệu\n",
    "    stop_words=\"english\",\n",
    "    use_idf=True\n",
    ")\n",
    "\n",
    "# Học từ vựng và biến đổi dữ liệu văn bản thành ma trận TF-IDF\n",
    "X = vectorizer.fit_transform(dataset.data)\n",
    "\n",
    "print(f\"Hoàn thành trong {time() - t0:.3f}s\")\n",
    "print(f\"Số lượng mẫu (tài liệu): {X.shape[0]}, Số lượng đặc trưng (từ): {X.shape[1]}\")\n",
    "print(f\"Kích thước ma trận TF-IDF: {X.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Bắt đầu gom cụm với K-Means (k=3)...\n",
      "Hoàn thành trong 0.412s\n"
     ]
    }
   ],
   "source": [
    "# 4. Áp dụng K-Means Clustering\n",
    "\n",
    "# Đặt số cụm bằng số nhóm tin đã biết\n",
    "k = n_clusters_true\n",
    "\n",
    "print(f\"\\nBắt đầu gom cụm với K-Means (k={k})...\")\n",
    "t0 = time()\n",
    "\n",
    "km = KMeans(\n",
    "    n_clusters=k,\n",
    "    init=\"k-means++\", # Khởi tạo cụm thông minh\n",
    "    max_iter=300,    # Số vòng lặp tối đa\n",
    "    n_init=10,       # Chạy 10 lần với các khởi tạo khác nhau, chọn lần tốt nhất\n",
    "    random_state=42  # Để kết quả ổn định\n",
    ")\n",
    "\n",
    "# Thực hiện gom cụm trên dữ liệu TF-IDF\n",
    "km.fit(X)\n",
    "\n",
    "print(f\"Hoàn thành trong {time() - t0:.3f}s\")\n",
    "\n",
    "# Lấy nhãn cụm được dự đoán cho từng tài liệu\n",
    "labels_pred = km.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Đánh giá kết quả gom cụm:\n",
      "Homogeneity: 0.391\n",
      "Completeness: 0.471\n",
      "V-measure: 0.428\n",
      "Adjusted Rand Index (ARI): 0.280\n",
      "Adjusted Mutual Information (AMI): 0.427\n",
      "Silhouette Coefficient: 0.010\n",
      "\n",
      "Inertia (Tổng bình phương khoảng cách đến tâm cụm): 2748.963\n"
     ]
    }
   ],
   "source": [
    "# 5. Đánh giá kết quả gom cụm\n",
    "\n",
    "print(\"\\nĐánh giá kết quả gom cụm:\")\n",
    "print(f\"Homogeneity: {metrics.homogeneity_score(labels_true, labels_pred):.3f}\")\n",
    "print(f\"Completeness: {metrics.completeness_score(labels_true, labels_pred):.3f}\")\n",
    "print(f\"V-measure: {metrics.v_measure_score(labels_true, labels_pred):.3f}\")\n",
    "print(f\"Adjusted Rand Index (ARI): {metrics.adjusted_rand_score(labels_true, labels_pred):.3f}\")\n",
    "print(f\"Adjusted Mutual Information (AMI): {metrics.adjusted_mutual_info_score(labels_true, labels_pred):.3f}\")\n",
    "\n",
    "# Silhouette Score cần ma trận dữ liệu X và nhãn dự đoán\n",
    "# Có thể chậm với dữ liệu lớn/chiều cao\n",
    "print(f\"Silhouette Coefficient: {metrics.silhouette_score(X, labels_pred, sample_size=1000):.3f}\") # Lấy mẫu 1000 điểm để tính nhanh hơn\n",
    "\n",
    "print(f\"\\nInertia (Tổng bình phương khoảng cách đến tâm cụm): {km.inertia_:.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
